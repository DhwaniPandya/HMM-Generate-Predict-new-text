# HMM-Generate-Predict-new-text
This is a combined project by Dhwani Pandya and Prashanthi Mallojula
Problem statement :
Hidden Mark.. M..
Probabilistic states and transitions
1. Set up a new git repository in your GitHub account
2. Pick a text corpus dataset such as
https://www.kaggle.com/kingburrito666/shakespeare-plays
or from https://github.com/niderhoff/nlp-datasets
3. Choose a programming language (Python, C/C++, Java)
4. Formulate ideas on how machine learning can be used to learn
word correlations and distributions within the dataset
5. Build a Hidden Markov Model to be able to programmatically
1. Generate new text from the text corpus
2. Perform text prediction given a sequence of words
6. Document your process and results
7. Commit your source code, documentation and other supporting
files to the git repository in GitHub

----------------------------------------------------------------------------------------------------------------------------------------
We have implemented this project in 3 parts.
1. We have generated new text sequence based on input sequence with which we trained our model with markov model,
   making use of markov chain property.
2. We have generated new text using forward-backward approach of hidden markov model.
3. We predicted the text based on the input sequence given with the viterbi algorithm of hmm. 
4. Have used different data sets for both algortihms


Note : I(Dhwani Pandya) have discussed briefly on this with Ronald Andrew and he recommended me to refer a link to clear my understanding.
